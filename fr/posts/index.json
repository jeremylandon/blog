[{"content":"On m\u0026rsquo;a r√©cemment pos√© la question sur \u0026ldquo;quelle est la \u0026ldquo;meilleure\u0026rdquo; m√©thode pour supprimer les √©l√©ments d\u0026rsquo;une collection √† taille variable\u0026rdquo;.\n myCollection.Clear() myCollection = new List() myCollection = null  Selon moi comme toujours il n\u0026rsquo;y a pas de \u0026ldquo;meilleure\u0026rdquo; solution ou m√™me de \u0026ldquo;m√©thode magique\u0026quot;, tout d√©pend de ce qu\u0026rsquo;on veut r√©ellement faire et ce qu\u0026rsquo;on veut transmettre comme message aux prochains d√©veloppeurs qui liront le code.\nNous ne traiterons pas le cas des collections thread safe de type ConcurrentBag \u0026amp; co. o√π la notion de concurrence rentre en jeu (en excluant ce point la logique reste identique).\r Avant toutes choses du point de vue de la performance et en prenant en crit√®re la volont√© de supprimer les √©l√©ments du tableau sans aller dans la micro-optimisation, les 3 m√©thodes peuvent √™tre consid√©r√©e comme √©quivalente = les √©l√©ments seront supprim√©s par le GC.\nAlors peu importe la solution √ßa ne change rien ? Non, car m√™me si la finalit√© sur les objets de la collection est la m√™me, au globale le r√©sultat est diff√©rent.\nVoici les classes utilis√©es dans les exemples, ces derni√®res ne sont utilis√©es que pour obtenir facilement un status visible de leur destruction.\nFoo\rTestList\rGetTestData\r\r1 2 3 4 5 6 7 8 9 10 11 12 13 14  public class Foo\r{\rprivate readonly int _id;\rpublic Foo(int id)\r{\r_id = id;\r}\r~Foo()\r{\rConsole.WriteLine($\u0026#34;Free Foo_{_id}\u0026#34;);\r}\r}\r  \r\r1 2 3 4 5 6 7  public class TestList\u0026lt;T\u0026gt; : List\u0026lt;T\u0026gt;\r{\r~TestList()\r{\rConsole.WriteLine(\u0026#34;Free TestList\u0026#34;);\r}\r}\r  \r\r1 2 3 4 5 6 7 8 9 10  private static TestList\u0026lt;Foo\u0026gt; GetTestData()\r{\rvar foos = new TestList\u0026lt;Foo\u0026gt;();\rfor (var i = 0; i \u0026lt; 2; i++)\r{\rfoos.Add(new Foo(i));\r}\rreturn foos;\r}\r  \r\r\r\r'use strict';\rvar containerId = JSON.parse(\"\\\"8b45b9a605ea83b5\\\"\");\rvar containerElem = document.getElementById(containerId);\rvar codetabLinks = null;\rvar codetabContents = null;\rvar ids = [];\rif (containerElem) {\rcodetabLinks = containerElem.querySelectorAll('.codetab__link');\rcodetabContents = containerElem.querySelectorAll('.codetab__content');\r}\rfor (var i = 0; i 0) {\rcodetabContents[0].style.display = 'block';\r}\r\nnull Assigner la collection √† null revient √† pousser un r√©f√©rence null et √† l\u0026rsquo;assigner √† notre variable.\nIL_00aa: ldnull\nIL_00ab: stloc.0\r1 2 3 4 5 6 7 8 9  var foos = GetTestData();\rfoos = null;\rGC.Collect();\rGC.KeepAlive(foos);\r// Free Foo_1\r// Free Foo_0\r// Free TestList\r  Cela signifie que notre collection initiale n\u0026rsquo;est plus rattach√©e aux GC Roots, elle sera donc consid√©r√©e comme morte au prochain passage du GC.\nEt comme cette derni√®re poss√®de des objets rattach√©s qui n\u0026rsquo;ont pas d\u0026rsquo;autres r√©f√©rences ils seront supprim√©s par la m√™me occasion.\nDonc cette m√©thode supprime la collection et les objets rattach√©s.\nIl est strictement inutile d\u0026rsquo;affecter un objet √† null en fin de scope, en effet une fois le scope pass√© l\u0026rsquo;objet n\u0026rsquo;est de fait plus rattach√© aux GC Roots (s\u0026rsquo;il n\u0026rsquo;est pas r√©f√©renc√© ailleurs).\r 1 2 3 4  {\rvar foos = GetTestData();\rfoos = null;\r}\r  Est identique √†\n1 2 3  {\rvar foos = GetTestData();\r}\r  new() Similaire √† la m√©thode pr√©c√©dente √† la diff√©rence que c\u0026rsquo;est une nouvelle instance de classe (=nouvelle r√©f√©rence) qui est pouss√©e dans la pile d'√©valuation et non null.\nIL_00aa: newobj\nIL_00ab: stloc.0\r1 2 3 4 5 6 7 8 9  var foos = GetTestData();\rfoos = new TestList\u0026lt;Foo\u0026gt;();\rGC.Collect();\rGC.KeepAlive(foos);\r// Free Foo_1\r// Free Foo_0\r// Free TestList\r  Comme avec null, la collection est supprim√©e d√ª au fait que sa r√©f√©rence n\u0026rsquo;est plus li√©e aux GC Roots et par effet de cha√Æne les objets rattach√©s aussi.\nClear() D\u0026rsquo;apr√®s la documentation cette m√©thode \u0026ldquo;supprime tous les √©l√©ments\u0026quot;.\nEn v√©rit√© elle remplace les r√©f√©rence avec la collection, c\u0026rsquo;est le GC qui supprimera les objets de la m√©moire.\nLe plus simple est de voir ce qui se passe en vrai.\n1 2 3 4 5 6 7 8  var foos = GetTestData();\rfoos.Clear();\rGC.Collect();\rGC.KeepAlive(foos);\r// Free Foo_1\r// Free Foo_0\r  Contrairement aux m√©thodes pr√©c√©dentes ici on ne touche pas √† la r√©f√©rence de la collection mais seulement aux r√©f√©rences des objets de celle-ci.\nR√©sultat la collection √©tant toujours li√© aux GC Roots, elle n\u0026rsquo;est pas lib√©r√©e mais comme les objets Foo_1 et Foo_2 ne sont plus li√©s √† la collection ni rien d\u0026rsquo;autre ils sont consid√©r√©s comme mort par le GC et ainsi se dernier les lib√®re.\nAussi la collection reste la m√™me de ce fait ces propri√©t√©s acquises dont sa r√©f√©rence ou la capacit√© reste inchang√©e.\nPour rappel une List est simplement un tableau qui se redimensionne √† la hausse automatiquement par r√©affectation.\nPar d√©faut la taille de ce tableau est de 4, si par l\u0026rsquo;accumulation de donn√©es le tableau est de taille 1000, il restera √† 1000 apr√®s le passage de la m√©thode Clear(), cela √©vite de r√©allouer des espaces lors des 1000 prochains ajouts, mais cela implique que vous avez un tableau de taille 1000 en m√©moire.\r R√©sum√©    m√©thode quand ?     null si vous souhaitez lib√©rer la m√©moire allou√©e par la collection et son contenu   new() si vous souhaitez lib√©rer la m√©moire allou√©e par la collection et son contenu tout en cr√©ant une nouvelle instance de la collection et implicitement une nouvelle capacit√© de base   clear() si vous souhaitez lib√©rer uniquement le contenu de la collection, en gardant les propri√©t√©s acquises de la collection    Conclusion Il est important de bien utiliser chacunes des 3 m√©thodes avec pertinence car elles aident √† la compr√©hension du code.\nMicro-optimisation mis √† part, le code doit avant tout √™tre compr√©hensible imm√©diatement.\n si je vois Clear() je comprend de suite la volont√© de supprimer le contenu si je vois new List\u0026lt;T\u0026gt;(400) je comprend directement la volont√© de repartir sur une collection vierge de taille 400 car dans le contexte 400 est la bonne taille et que pr√©c√©demment la collection √©tait bien trop grosse si je vois null c\u0026rsquo;est que la collection ne sera plus utilis√©es plus tard dans le code et potentiellement que sa taille est probl√©matique \u0026hellip;  Si on s\u0026rsquo;attarde sur la micro-optimisation (on parle de seulement quelques Ticks\u0026hellip;) un new List\u0026lt;T\u0026gt;(x) est plus performant qu\u0026rsquo;un Clear() car dans ce dernier un parcour du tableau est requis (avec une compl√©xit√© O(n)), en revanche le message fourni aux prochains d√©veloppeurs peut √™tre ambigu√´ √† la premi√®re lecture (en bref cela ne vaut pas le coup dans la quasi totalit√© des cas).\nSources Documentation  https://en.wikipedia.org/wiki/Tracing_garbage_collection https://docs.microsoft.com/en-us/dotnet/standard/garbage-collection/fundamentals https://github.com/dotnet/runtime/blob/master/src/libraries/System.Collections/src/System/Collections/Generic/SortedList.cs https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.list-1.capacity  ","description":"On m'a r√©cemment pos√© la question sur quelle est la ‚Äúmeilleur‚Äù m√©thode pour supprimer les √©l√©ments d'une collection √† taille variable.","id":7,"section":"posts","tags":["dotnet","csharp","performance","benchmark"],"title":"[.NET] Comment r√©initialiser une collection proprement: clear(), new() ou null ?","uri":"https://blog.jeremylandon.com/fr/2020/04/20/dotnet-comment-reinitialiser-une-collection-proprement-clear-new-ou-null/"},{"content":"Vous avez rencontr√© cette erreur en essayant de cr√©er une nouveau conteneur sur l'√©mulateur local de Cosmos DB:\n\u0026ldquo;Sorry, we are currently experiencing high demand in this region, and cannot fulfill your request at this time. We work continuously to bring more and more capacity online, and encourage you to try again\u0026rdquo;\r\nAugmenter le nombre de conteneur Par d√©faut l'√©mulateur Cosmos DB ne g√®re que 25 conteneurs de taille fixe ou 5 conteneurs illimit√©s (ou un mixe des deux sachant qu\u0026rsquo;un conteneur de taille illimit√© √©quivaut √† 5 conteneurs de taille fixe).\nIl est possible d\u0026rsquo;augmenter cette limite jusqu'√† 250 conteneurs de taille fixe (en acceptant de supprimer toutes ces collections), pour ce faire :\n Quittez l'√©mulateur Cosmos: cela prend plusieurs longues minutes =\u0026gt; le plus rapide est d\u0026rsquo;arr√™ter les processus Cosmos DB comme un cochon üêΩ (Azure Cosmos Master Service / Azure Cosmos Server Service / DocumentDB.GatewayService / Microsoft Azure Cosmos Emulator). Supprimez les donn√©es de l'√©mulateur en supprimant tous les fichiers de ce dossier: %LOCALAPPDATA%\\CosmosDBEmulator. Lancer l'√©mulateur avec les param√®tre PartitionCount \u0026lt;= 250.  1 2 3 4 5 6 7 8 9 10 11  \u0026lt;# kill cosmos like a üêΩ #\u0026gt;\rtaskkill /im \u0026#34;CosmosDB.Emulator.exe\u0026#34; /f\rtaskkill /im \u0026#34;Microsoft.Azure.Cosmos.Server.exe\u0026#34; /f\rtaskkill /im \u0026#34;Microsoft.Azure.Cosmos.Master.exe\u0026#34; /f\rtaskkill /im \u0026#34;Microsoft.Azure.Cosmos.GatewayService.exe\u0026#34; /f\r\u0026lt;# remove cosmos datas #\u0026gt;\rRemove-Item \u0026#34;$env:LOCALAPPDATA\\CosmosDBEmulator\\*\u0026#34; -Recurse -Force\r\u0026lt;# run cosmos with 250 partitions #\u0026gt;\r\u0026amp; \u0026#34;C:\\Program Files\\Azure Cosmos DB Emulator\\CosmosDB.Emulator.exe\u0026#34; /PartitionCount=250\r  Voil√†! üëå\nLa limite du nombre de conteneur est mise en place pour limiter les ressources allou√©es √† l'√©mulateur.\r Sources Documentation  https://stackoverflow.com/a/51617916/4181832 https://docs.microsoft.com/en-us/azure/Cosmos-db/local-emulator  ","description":"\"Sorry, we are currently experiencing high demand in this region, and cannot fulfill your request at this time. We work continuously to bring more and more capacity online, and encourage you to try again\"","id":8,"section":"posts","tags":["azure","Cosmos","exception"],"title":"[Azure] Comment augmenter le nombre de conteneur sur l'√©mulateur Cosmos DB","uri":"https://blog.jeremylandon.com/fr/2020/04/12/azure-comment-augmenter-le-nombre-de-conteneur-sur-lemulateur-cosmos-db/"},{"content":"Les erreurs HTTP 429 se produisent lorsque la consommation sur un conteneur est sup√©rieure au d√©bit provisionn√©.\nConsommation en RU par seconde  RU provisionn√© par seconde = HTTP 429.\r\nAvant tout de chose, est-ce grave ?\nTout d√©pend de la situation, la finalit√© d\u0026rsquo;une erreur 429 est que la requ√™te n\u0026rsquo;a pas √©t√© ex√©cut√©e, cela peut √™tre probl√©matique dans des contextes o√π la coh√©rence des donn√©es est importante (ex: ajout d\u0026rsquo;un profil utilisateur), mais moins si elle ne l\u0026rsquo;est pas (ex: une vue sur une vid√©o durant un pic de trafic de quelques secondes).\nLes r√©flexes √† adopter Optimiser les requ√™tes Optimiser les RU Le RU (unit√© de requ√™te/request unit) est l\u0026rsquo;unit√© de devise du d√©bit. Elle est calcul√©e via diff√©rents facteurs qui sont tr√®s bien d√©taill√©s sur le site de Microsoft.\nsource:\rhttps://docs.microsoft.com/en-us/azure/cosmos-db/request-units\r\r\nM√™me en connaissant tout les facteurs il faut prendre en compte que la formule de calcul reste chez Microsoft, de ce fait il est tr√®s difficile de pr√©dire √† l\u0026rsquo;avance combien pr√©cis√©ment une requ√™te consomme en RU.\nN√©anmoins il est possible de conna√Ætre la consommation d\u0026rsquo;une requ√™te apr√®s l\u0026rsquo;avoir ex√©cut√©e et d\u0026rsquo;adapter en fonction en examinant l\u0026rsquo;en-t√™te x-ms-request-charge de la r√©ponse.\nCette donn√©e est aussi disponible via le portail lors de l\u0026rsquo;ex√©cution d\u0026rsquo;une requ√™te:\nEt directement via le SDK au travers de la propri√©t√© RequestCharge.\n1 2  var response = await conteneur.CreateItemAsync(foo, new PartitionKey(foo.Pk));\rvar ru = response.RequestCharge;\r  La fr√©quence La fr√©quence de lancement des requ√™tes est primordiale et aussi la plus compliqu√©e √† d√©terminer (nous n\u0026rsquo;allons ici pas parler des Bulk insert/update qui feront l\u0026rsquo;objet d\u0026rsquo;un autre article).\nSupposons le cas o√π vous ayez 50 requ√™tes √† 10 RU chacune, sur une provision √† 400 RU/s le lancement de toutes les requ√™tes en parall√®le provoquera des erreurs 429.\nDeux solutions sont possibles : augmenter temporairement le provisionnement ou lisser les requ√™tes dans le temps (par seconde).\nNous allons nous attarder sur la deuxi√®me solution: le lissage dans le temps n\u0026rsquo;a pas pour but de s√©quentialiser 1 √† 1 nos requ√™tes, ou faire 1 requ√™te par seconde, √ßa serait une catastrophe niveau performance et nous perdrions tout l\u0026rsquo;int√©r√™t de la puissance du parall√©lisme que nous offre Cosmos DB, l\u0026rsquo;objectif sera de trouver le bon compromis entre performance et usage selon notre contexte et nos ressources.\nIl faudra donc se poser la question suivante:\nCombien de RU puis-je consommer par seconde sans que cela ne provoque d\u0026rsquo;erreurs/latences ailleur dans mon application ?\rBien √©videmment il n\u0026rsquo;y a pas de r√©ponse universelle √† cette question, tout d√©pend de votre contexte (ressources / usages / fr√©quences\u0026hellip;).\nMais une fois la r√©ponse trouv√©e ou suppos√©ment trouv√©e voici une m√©thode d\u0026rsquo;extension que vous pouvez retrouver sur mon gist qui permet de limiter le nombre de t√¢che en parall√®le de mani√®re temporis√©e et ainsi r√©pondre par exemple au besoin: \u0026ldquo;je veux X traitements toutes les secondes\u0026quot;.\n 1 2 3 4 5 6 7 8 9  var maxDegreeOfParallelism = 10;\r// the RUs is limited by second.\rvar millisecondsDelay = TimeSpan.FromSeconds(1).TotalMilliseconds;\rawait Enumerable.Range(0, 50).DelayParallelForEachAsync(async (index) =\u0026gt;\r{\rvar foo = Foo.Create(Guid.NewGuid().ToString());\rawait conteneur.CreateItemAsync(foo, new PartitionKey(foo.Pk));\r}, maxDegreeOfParallelism, millisecondsDelay);\r  Recommencer La solution la plus simple et courante est tout simplement de relancer la requ√™te.\nEn effet en partant du principe que le conteneur n\u0026rsquo;est pas sous-provisionn√©, des erreurs 429 peuvent arriver occasionnellement lors d\u0026rsquo;une activit√© √† fort trafic.\nDans cette situation rien ne sert de sur-dimensionner le conteneur (et ainsi payer plus) pour √©viter un probl√®me qui intervient seulement quelques secondes dans la journ√©e.\nL\u0026rsquo;erreur HTTP 429 est accompagn√©e de l\u0026rsquo;en-t√™te x-ms-retry-after-ms qui indique dans combien de temps il sera possible de relancer la requ√™te.\nHeureusement cette logique de relancement est d√©j√† g√©r√©e par le SDK via la propri√©t√© MaxRetryAttemptsOnRateLimitedRequests\nLe nombre de nouvelles tentatives pour une requ√™te est par d√©faut de 9 sur le SDK.\r 1 2 3 4  CosmosClient cosmosClient = new CosmosClient(ConnectionString, new CosmosClientOptions()\r{\rMaxRetryAttemptsOnRateLimitedRequests = 30\r});\r  Super donc je n\u0026rsquo;ai qu'√† mettre cette propri√©t√© √† 1 000 000 et le probl√®me est r√©gl√© !\rEn th√©orie oui‚Ä¶ mais dans la quasi-totalit√© des cas c\u0026rsquo;est une tr√®s mauvaise id√©e. En effet cr√©er un tr√®s grand nombre de tentative :\n augmente le d√©lai d\u0026rsquo;ex√©cution des requ√™tes (429 -\u0026gt; attendre 100ms -\u0026gt; 429 -\u0026gt; attendre 100ms -\u0026gt; [‚Ä¶] -\u0026gt; OK) peut provoquer des effets de bord tr√®s graves sur l\u0026rsquo;application (lenteurs, threads bloqu√©s, timeout‚Ä¶) fait office de cache mis√®re et ainsi masque le fait que votre conteneur est sous-provisionn√©  Concernant le nombre √† mettre, il n\u0026rsquo;y a pas de ‚Äúnombre magique‚Äù cela est √† adapter en fonction du besoin (Microsoft recommande n√©anmoins par exemple de passer cette valeur √† 30 durant l\u0026rsquo;insertion d\u0026rsquo;un grand nombre d\u0026rsquo;entit√©).\nAutoPilot En preview √† l'√©criture de cet article, Cosmos AutoPilot permet de mettre √† l'√©chelle automatiquement le conteneur selon une plage de RU donn√©e.\nIl faut n√©anmoins prendre en compte plusieurs aspects de AutoPilot:\n Il poss√®de sa propre tarification (plus √©lev√©e que le provisionn√©) Il n\u0026rsquo;emp√™che pas les 429 mais les limites fortement (dans l\u0026rsquo;illustration si vous d√©pass√© les 4000 RU/s les requ√™tes passeront en 429) A l'√©criture de l\u0026rsquo;article il n\u0026rsquo;est pas encore possible de provisionner un conteneur en AutoPilot via le SDK (mais ceci est pr√©vu)  Augmenter le provisionnement Si malgr√© toutes les actions pr√©c√©dentes des erreurs 429 apparaissent toujours et sont probl√©matiques, alors cela signifie simplement que votre conteneur est sous provisionn√©e par rapport √† votre besoin.\nPour aider √† choisir le provisionnement adapt√© Microsoft met √† disposition une calculatrice √† capacit√©: https://cosmos.azure.com/capacitycalculator/.\nConclusion Les erreurs HTTP 429 ne posent pas de probl√®mes tant qu\u0026rsquo;elles sont g√©r√©es et restent occasionnelles.\nElles doivent avant toute chose √™tre un point d\u0026rsquo;alerte pour se poser des questions sur les performances du code/requ√™tes et le provisionnement des conteneurs.\nSources Repository  https://gist.github.com/Golapadeog/7228a17b6287619f71ffd1ba60e4faa2  Documentation  https://docs.microsoft.com/en-us/azure/cosmos-db/performance-tips https://docs.microsoft.com/en-us/azure/cosmos-db/provision-throughput-autopilot https://docs.microsoft.com/en-us/azure/cosmos-db/autopilot-faq https://docs.microsoft.com/en-us/azure/cosmos-db/optimize-cost-queries https://docs.microsoft.com/en-us/azure/cosmos-db/request-units https://cosmos.azure.com/capacitycalculator/  ","description":"","id":9,"section":"posts","tags":["azure","dotnet","csharp","performance","cosmos"],"title":"[Azure] Comment g√©rer les erreurs 429 sur Azure Cosmos DB","uri":"https://blog.jeremylandon.com/fr/2020/04/06/azure-comment-gerer-les-erreurs-429-sur-azure-cosmos-db/"},{"content":"Le traitement d\u0026rsquo;un fichier csv de plusieurs Go peut vite √™tre co√ªteux en terme de performance.\nPour rappel un fichier csv n\u0026rsquo;est pas seulement un format qui s√©pare ses colonnes par un caract√®re, mais c\u0026rsquo;est aussi:\n des ent√™tes pr√©sentes ou non, des colonnes parfois inexistantes, des lignes vides, des guillemets pour repr√©senter une colonne, des guillemets dans des guillemets pour repr√©senter des guillemets dans une colonne‚Ä¶ ‚Ä¶  Bref, la liste est encore longue et √ßa peut vite devenir un vrai casse t√™te de g√©rer tous les cas.\nA cela s\u0026rsquo;ajoute qu\u0026rsquo;il faut la plupart du temps lier les colonnes √† des objets de notre code, que dans le cas d\u0026rsquo;un tr√®s gros fichier il n\u0026rsquo;est pas envisageable de charger le fichier en m√©moire et qu\u0026rsquo;il faudra lire √† m√™me le stream ce qui peut apporter d\u0026rsquo;autres probl√©matiques (heureusement en .NET cette derni√®re probl√©matique reste extr√™mement simple √† solutionner) cela peut devenir relativement compliqu√©.\nBien entendu d\u0026rsquo;autres se sont pris la t√™te l√†-dessus, c\u0026rsquo;est pour cette raison qu\u0026rsquo;il existe un grand nombre de framework de lecture/√©criture de fichier csv qui g√®re la totalit√© des probl√©matiques li√©es √† ce format.\nTextFieldParser Le framework .NET propose une solution de base avec TextFieldParser.\nSampleCsvParser\rFoo\r\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  [Benchmark]\rpublic void TextFieldParser()\r{\rusing var streamReader = new StreamReader(_csvFilePath);\rTextFieldParser parser = new TextFieldParser(_csvFilePath)\r{\rHasFieldsEnclosedInQuotes = true,\rDelimiters = new[] { \u0026#34;,\u0026#34; }\r};\rstring[] fields;\rwhile ((fields = parser.ReadFields()) != null)\r{\rFoo.CreateFromFields(fields);\r// ...\r }\r}\r  \r\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  public class Foo\r{\rpublic string Prop0 { get; set; }\rpublic string Prop1 { get; set; }\rpublic string Prop2 { get; set; }\rpublic static Foo CreateFromFields(string[] fields)\r{\rreturn new Foo\r{\rProp0 = fields[0],\rProp1 = fields[1],\rProp2 = fields[2],\r};\r}\r}\r  \r\r\r\r'use strict';\rvar containerId = JSON.parse(\"\\\"1fd23b22d09bf43d\\\"\");\rvar containerElem = document.getElementById(containerId);\rvar codetabLinks = null;\rvar codetabContents = null;\rvar ids = [];\rif (containerElem) {\rcodetabLinks = containerElem.querySelectorAll('.codetab__link');\rcodetabContents = containerElem.querySelectorAll('.codetab__content');\r}\rfor (var i = 0; i 0) {\rcodetabContents[0].style.display = 'block';\r}\r CsvHelper sources: https://github.com/JoshClose/CsvHelper\nSampleCsvParser\rFooMapping\r\r1 2 3 4 5 6 7 8 9 10 11 12 13  [Benchmark]\rpublic void CsvHelper()\r{\rusing var streamReader = new StreamReader(_csvFilePath);\rvar csvconfig = new CsvConfiguration(CultureInfo.CurrentCulture) { Delimiter = \u0026#34;,\u0026#34;, HasHeaderRecord = false };\rcsvconfig.RegisterClassMap\u0026lt;CsvHelperFooMapping\u0026gt;();\rvar csv = new CsvReader(streamReader, csvconfig);\rusing var records = csv.GetRecords\u0026lt;Foo\u0026gt;().GetEnumerator();\rwhile (records.MoveNext())\r{\r// ...\r }\r}\r  \r\r1 2 3 4 5 6 7 8 9  public sealed class CsvHelperFooMapping: ClassMap\u0026lt;Foo\u0026gt;\r{\rpublic CsvHelperFooMapping()\r{\rMap(x =\u0026gt; x.Prop0).Index(0);\rMap(x =\u0026gt; x.Prop1).Index(1);\rMap(x =\u0026gt; x.Prop2).Index(2);\r}\r}\r  \r\r\r\r'use strict';\rvar containerId = JSON.parse(\"\\\"38c07b8d75d8a1cb\\\"\");\rvar containerElem = document.getElementById(containerId);\rvar codetabLinks = null;\rvar codetabContents = null;\rvar ids = [];\rif (containerElem) {\rcodetabLinks = containerElem.querySelectorAll('.codetab__link');\rcodetabContents = containerElem.querySelectorAll('.codetab__content');\r}\rfor (var i = 0; i 0) {\rcodetabContents[0].style.display = 'block';\r}\r TinyCsvParser sources: https://github.com/bytefish/TinyCsvParser\nSampleCsvParser\rFooMapping\r\r1 2 3 4 5 6 7 8 9 10 11  public void TinyCsvParser()\r{\rvar csvParserOptions = new CsvParserOptions(false, \u0026#39;,\u0026#39;, Environment.ProcessorCount, false);\rvar csvMapper = new TinyFooMapping();\rvar csvParser = new CsvParser\u0026lt;Foo\u0026gt;(csvParserOptions, csvMapper);\rusing var records = csvParser.ReadFromFile(_csvFilePath, Encoding.UTF8).GetEnumerator();\rwhile (records.MoveNext())\r{\r// ...\r }\r}\r  \r\r1 2 3 4 5 6 7 8 9  public sealed class TinyFooMapping : CsvMapping\u0026lt;Foo\u0026gt;\r{\rpublic TinyFooMapping()\r{\rMapProperty(0, x =\u0026gt; x.Prop0);\rMapProperty(1, x =\u0026gt; x.Prop1);\rMapProperty(2, x =\u0026gt; x.Prop2);\r}\r}\r  \r\r\r\r'use strict';\rvar containerId = JSON.parse(\"\\\"88b9138043c8439a\\\"\");\rvar containerElem = document.getElementById(containerId);\rvar codetabLinks = null;\rvar codetabContents = null;\rvar ids = [];\rif (containerElem) {\rcodetabLinks = containerElem.querySelectorAll('.codetab__link');\rcodetabContents = containerElem.querySelectorAll('.codetab__content');\r}\rfor (var i = 0; i 0) {\rcodetabContents[0].style.display = 'block';\r}\r R√©sultat (100 000 lignes + ssd)    Method Mean %     TextFieldParser 6,617.43 ms 0%   CsvHelper 4,018.37 ms -39 %   TinyCsvParser 1,062.29 ms -84 %    Doit-on d\u0026rsquo;office exclure CsvHelper?\nNon, comme toujours en d√©veloppement rien n\u0026rsquo;est blanc ou noir.\nDans ce cas sp√©cifique (un csv propre, une configuration de base et une lecture d\u0026rsquo;un gros fichier) TinyCsvParser est pr√©f√©rable en revanche dans d\u0026rsquo;autres sc√©narii CsvHelper apporte des fonctionnalit√©s tr√®s int√©ressantes (comme l\u0026rsquo;auto-mapping) qui peuvent faire gagner un pr√©cieux temps de d√©veloppement et de maintenance.\nBref cela d√©pend de la situation comme toujours.\nMais comment expliquer de tels d√©calages ? Principalement cela est d√ª au traitement des lignes du CSV pour g√©rer tous les cas et la cr√©ation des entit√©s.\nNous avons tendance √† se ruer sur des framework pour des choses simples, ces framework sont l√† pour g√©rer tous les cas ce qui apporte un confort de d√©veloppement, de la fiabilit√© mais malheureusement aussi une lourdeur dans les traitements.\nJ\u0026rsquo;ai r√©cemment d√ª parser un fichier de 30Go \u0026ldquo;propre\u0026rdquo; (virgule + parfois des guillemets) dont je connais parfaitement le format, et j\u0026rsquo;ai voulu voir combien co√ªte \u0026ldquo;la gestion de tous les cas\u0026rdquo;.\nSolution personnalis√©e SampleCsvParser\rExtractFields\r\r1 2 3 4 5 6 7 8 9 10 11  [Benchmark]\rpublic void Custom()\r{\rusing var streamReader = new StreamReader(_csvFilePath);\rstring line;\rwhile ((line = streamReader.ReadLine()) != null)\r{\rFoo.CreateFromCsvLine(line);\r// ...\r }\r}\r  \r\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  public class Foo\r{\r...\rpublic static Foo CreateFromCsvLine(string line)\r{\rreturn CreateFromFields(ExtractFields(line, 3));\r}\rprivate static string[] ExtractFields(string line, int propertyCount)\r{\rvar result = new string[propertyCount];\rvar index = 0;\rbool isInQuotes = false;\rvar chars = line.ToCharArray();\rStringBuilder str = new StringBuilder(string.Empty);\rforeach (var t in chars)\r{\rif (t == \u0026#39;\u0026#34;\u0026#39;)\r{\risInQuotes = !isInQuotes;\r}\relse if (t == \u0026#39;,\u0026#39; \u0026amp;\u0026amp; !isInQuotes)\r{\rresult[index++] = str.ToString();\rstr.Clear();\r}\relse\r{\rstr.Append(t);\r}\r}\rresult[index] = str.ToString();\rreturn result;\r}\r}\r  \r\r\r\r'use strict';\rvar containerId = JSON.parse(\"\\\"7ae383d0c6fbde5f\\\"\");\rvar containerElem = document.getElementById(containerId);\rvar codetabLinks = null;\rvar codetabContents = null;\rvar ids = [];\rif (containerElem) {\rcodetabLinks = containerElem.querySelectorAll('.codetab__link');\rcodetabContents = containerElem.querySelectorAll('.codetab__content');\r}\rfor (var i = 0; i 0) {\rcodetabContents[0].style.display = 'block';\r}\r L\u0026rsquo;algorithme d\u0026rsquo;analyse des lignes csv est simple et limit√©e mais correspond √† mon besoin.\nEt voici le r√©sultat :\n   Method Mean %     TextFieldParser 6,617.43 ms 0%   CsvHelper 4,018.37 ms -39 %   TinyCsvParser 1,062.29 ms -84 %   Custom 1,083.97 ms -83 %    Comment TinyCsvParser peut-il encore √™tre plus performant ? Simplement car ce framework utilise de base le parall√©lisme. Nous allons en faire de m√™me pour la science.\nSolution personnalis√©e avec parall√©lisme SampleCsvParser\rStreamReaderEnumerator\r\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  [Benchmark]\rpublic void CustomParallel()\r{\rusing var streamReader = new StreamReader(_csvFilePath);\rvar enumerator = new StreamReaderEnumerable(streamReader);\rvar po = new ParallelOptions\r{\r// just for demo\r MaxDegreeOfParallelism = Environment.ProcessorCount\r};\rvar action = new Action\u0026lt;string\u0026gt;(line =\u0026gt;\r{\rFoo.CreateFromCsvLine(line);\r// ...\r });\rParallel.ForEach(enumerator, po, action);\r}\r  \r\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109  /// \u0026lt;summary\u0026gt;\r/// This method comes from \u0026lt;see href=\u0026#34;!:https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.ienumerable-1.etenumerator\u0026#34;\u0026gt;msdn\u0026lt;/see\u0026gt;\r/// \u0026lt;/summary\u0026gt;\rpublic class StreamReaderEnumerable : IEnumerable\u0026lt;string\u0026gt;\r{\rprivate readonly StreamReader _sr;\rpublic StreamReaderEnumerable(StreamReader streamReader)\r{\r_sr = streamReader;\r}\r// Must implement GetEnumerator, which returns a new StreamReaderEnumerator.\r public IEnumerator\u0026lt;string\u0026gt; GetEnumerator()\r{\rreturn new StreamReaderEnumerator(_sr);\r}\r// Must also implement IEnumerable.GetEnumerator, but implement as a private method.\r private IEnumerator GetEnumerator1()\r{\rreturn GetEnumerator();\r}\rIEnumerator IEnumerable.GetEnumerator()\r{\rreturn GetEnumerator1();\r}\r}\r/// \u0026lt;summary\u0026gt;\r/// This method comes from \u0026lt;see href=\u0026#34;!:https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.ienumerable-1.etenumerator\u0026#34;\u0026gt;msdn\u0026lt;/see\u0026gt;\r/// \u0026lt;/summary\u0026gt;\rpublic class StreamReaderEnumerator : IEnumerator\u0026lt;string\u0026gt;\r{\rprivate readonly StreamReader _sr;\rpublic StreamReaderEnumerator(StreamReader streamReader)\r{\r_sr = streamReader;\r}\rprivate string _current;\r// Implement the IEnumerator(T).Current publicly, but implement\r // IEnumerator.Current, which is also required, privately.\r public string Current\r{\rget\r{\rif (_sr == null || _current == null)\r{\rthrow new InvalidOperationException();\r}\rreturn _current;\r}\r}\rprivate object Current1 =\u0026gt; this.Current;\robject IEnumerator.Current =\u0026gt; Current1;\r// Implement MoveNext and Reset, which are required by IEnumerator.\r public bool MoveNext()\r{\r_current = _sr.ReadLine();\rreturn _current != null;\r}\rpublic void Reset()\r{\r_sr.DiscardBufferedData();\r_sr.BaseStream.Seek(0, SeekOrigin.Begin);\r_current = null;\r}\r// Implement IDisposable, which is also implemented by IEnumerator(T).\r private bool _disposedValue;\rpublic void Dispose()\r{\rDispose(true);\rGC.SuppressFinalize(this);\r}\rprotected virtual void Dispose(bool disposing)\r{\rif (!_disposedValue)\r{\rif (disposing)\r{\r// Dispose of managed resources.\r }\r_current = null;\rif (_sr != null)\r{\r_sr.Close();\r_sr.Dispose();\r}\r}\r_disposedValue = true;\r}\r~StreamReaderEnumerator()\r{\rDispose(false);\r}\r}\r  \r\r\r\r'use strict';\rvar containerId = JSON.parse(\"\\\"29ef42505ab95160\\\"\");\rvar containerElem = document.getElementById(containerId);\rvar codetabLinks = null;\rvar codetabContents = null;\rvar ids = [];\rif (containerElem) {\rcodetabLinks = containerElem.querySelectorAll('.codetab__link');\rcodetabContents = containerElem.querySelectorAll('.codetab__content');\r}\rfor (var i = 0; i 0) {\rcodetabContents[0].style.display = 'block';\r}\r    Method Mean %     TextFieldParser 6,617.43 ms 0%   CsvHelper 4,018.37 ms -39 %   TinyCsvParser 1,062.29 ms -84 %   Custom 1,083.97 ms -83 %   CustomParallel 632.97 ms -90 %    Le temps est divis√© par 2 par rapport √† TinyCsvParser. Au final, sur mon fichier de 30Go je suis pass√© de 7min √† 3min20 de traitement de mani√®re simple.\r Conclusion Les performances d\u0026rsquo;une solution personnalis√©e laissent r√™veur, n√©anmoins ce code ne r√©pond qu'√† un seul et unique cas: les tr√®s gros fichiers csv propre et simple.\nMais dans le cas o√π vous ayez un grand nombre de fichier csv avec des \u0026ldquo;qualit√©s\u0026rdquo; variables, il est fortement recommand√© de passer par un framework tel que CsvHelper ou TinyCsvParser o√π un grand nombre de bons d√©veloppeurs ont pu analyser les performances de chaque ligne de code permettant de g√©rer tout les cas.\nNB: Il est int√©ressant de se rendre compte que le classement est totalement chamboul√© sur des petits fichiers csv (exemple avec un csv de 10 lignes):\r   Method Mean %     TextFieldParser 253.18 us 0%   CsvHelper 991.40 us +291 %   TinyCsvParser 653.78 us +158 %   Custom 50.99 us -79 %   CustomParallel 113.25 us -55 %    Ce qui prouve encore qu\u0026rsquo;il n\u0026rsquo;y a pas de magie en d√©veloppement, que tout d√©pend du contexte et annexement que le parall√©lisme est tr√®s souvent profitable et recommand√© mais peut aussi √™tre un pi√®ge.\r Sources Documentation  https://docs.microsoft.com/en-us/dotnet/api/microsoft.visualbasic.fileio.textfieldparser https://github.com/JoshClose/CsvHelper https://github.com/bytefish/TinyCsvParser https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.ienumerable-1.getenumerator https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/potential-pitfalls-in-data-and-task-parallelism  ","description":"","id":10,"section":"posts","tags":["dotnet","csharp","algorithm","performance","benchmark"],"title":"[.NET] Comment lire un tr√®s gros fichier csv","uri":"https://blog.jeremylandon.com/fr/2020/03/30/dotnet-comment-lire-un-tres-gros-fichier-csv/"},{"content":"Une des fa√ßons les plus simples et courantes d\u0026rsquo;utiliser les services de messagerie tels qu\u0026rsquo;Azure Service Bus est pour effectuer une communication unidirectionnel.\nsource:\rhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messaging-overview\r\r\nExemple: Bob en tant qu\u0026rsquo;envoyeur de message et Eve en tant que r√©ceptionniste.\n1. Eve √©coute la file d\u0026rsquo;attente Q1\n2. Bob envoie un message sur Q1\n3. Eve re√ßoit le message de Bob √† partir Q1\nMais comment Bob peut-il savoir que le traitement de Eve est termin√© ?\nOu plus g√©n√©ralement comment ces 2 services peuvent-ils communiquer de mani√®re bidirectionnelle? C\u0026rsquo;est l√† que le pattern Request/Response (ou Request/Reply) intervient.\nLe pattern Request/Response Ce pattern utilise un routage de message afin d\u0026rsquo;obtenir une communication bidirectionnel entre deux services.\nFonctionnellement c\u0026rsquo;est tr√®s simple, l\u0026rsquo;envoyeur envoie un message sur une file d\u0026rsquo;attente et attend une r√©ponse sur une autre file d\u0026rsquo;attente.\nsource:\rhttps://www.enterpriseintegrationpatterns.com/patterns/messaging/RequestReplyJmsExample.html\r\r\nIl existe 4 types de routage principaux qui sont tr√®s bien d√©taill√©s ici : https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messages-payloads\nDans la version \u0026ldquo;la plus simple\u0026rdquo; (Request/Response simple), il n\u0026rsquo;existe aucune garantie que Bob re√ßoit son message de r√©ponse. En effet si un nouvel utilisateur nomm√© Alice √©coute la m√™me file d\u0026rsquo;attente, elle pourrait intercepter le message destin√© √† Bob.\nConcurrence entre Bob et Alice:\r\r\nNaturellement une id√©e pourrait venir en t√™te assez rapidement : Bob cr√©√© une file d\u0026rsquo;attente √† lui et attend la r√©ponse dessus. Une fois la r√©ponse obtenue il supprime la file d\u0026rsquo;attente.\nC\u0026rsquo;est une logique correcte, mais qui n\u0026rsquo;est pas √† faire, car:\n elle implique une gestion des services morts (que faire si le processus crash sans avoir supprim√© son service ? Nous devons d√©velopper un cleaner en externe ? Doit-on supprimer le service avec les lettres mortes associ√©es qui fournissent de pr√©cisieuses informations pour r√©gler un potentiel bug ?\u0026hellip;) elle n\u0026rsquo;est √©videmment pas performante (il faudra √† chaque fois cr√©er et supprimer la queue, dans des fr√©quences parfois √©lev√©es) elle introduit une pollution du Service Bus Namespace qui le rend difficile/impossible √† analyser les Service Bus Namespace ont une limite sur la quantit√© de file d\u0026rsquo;attente/topic pouvant √™tre cr√©√© \u0026hellip;etc  En bref beaucoup de probl√®mes pour une solution personnalis√©e, et le standard est toujours √† privil√©gier. N\u0026rsquo;en existe-t-il pas un ?\nJustement si, grace au protocole AMQP qui apporte une notion de groupe, retranscrite chez Microsoft sous le nom session qui r√©sout tr√®s simplement et rapidement cette probl√©matique.\nLes sessions (groupe) Pour garantir que Bob soit le seul √† r√©cup√©rer le message de r√©ponse qui lui est destin√©, nous allons utiliser les sessions (ou plus pr√©cisement les groupes du protocole AMQP), qui pour faire simple apporte une multipl√©xage et ainsi plusieurs utilisateurs peuvent √©couter la m√™me file tout en ayant chacun leur propre groupe de message.\nBob √©coute et verrouille une session sp√©cifique sur la file d\u0026rsquo;attente, ainsi lui seul pourra √©couter ses messages (√† l\u0026rsquo;image d\u0026rsquo;une sous file d\u0026rsquo;attente r√©serv√©e √† Bob).\nBob devra fournir des informations suppl√©mentaires √† son message afin que le r√©ceptionneur (Eve) puisse envoyer correctement le message de r√©ponse.\nTechniquement cela se traduit par deux propri√©t√©s d√©finies par le protocole AMQP 1.0 :\nle nom des champs du protocole AMQP ne sont pas forcement les m√™mes que ceux de l\u0026rsquo;API (ex: group-id dans le protocole = SessionId dans l\u0026rsquo;API)\r  ReplyTo (reply-to): chemin d\u0026rsquo;acc√®s o√π Bob attend la r√©ponse. Eve y enverra son message de r√©ponse. ReplyToSessionId (reply-to-group-id): l\u0026rsquo;id de la session √©cout√©e par Bob. Eve assignera cette valeur √† la propri√©t√© SessionId (group-id) de son message de r√©ponse.  Exemple L\u0026rsquo;exemple sera r√©alis√© avec Microsoft.Azure.ServiceBus et de deux files d\u0026rsquo;attente.\nTechniquement il est indispensable que la file d\u0026rsquo;attente de r√©ponse n\u0026rsquo;accepte que les sessions.\nCela peut se faire via le portail Azure.\nsource:\rhttps://docs.microsoft.com/en-us/azure/service-bus-messaging/message-sessions\r\r\nOu via le code avec la propri√©t√© RequiresSession.\n1 2 3 4 5  var managementClient = new ManagementClient(connectionString);\rawait managementClient.CreateQueueAsync(new QueueDescription(queueName)\r{\rRequiresSession = true\r});\r  Creation des files d\u0026rsquo;attente Dans un premier temps nous allons cr√©er pour la d√©monstration 2 files d\u0026rsquo;attente:\n sample.request: sans session, utilis√©e pour envoyer les messages de Bob √† traiter par Eve. sample.retry: avec session, utilis√©e pour envoyer la r√©ponse √† Bob.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  static async Task Main()\r{\rvar connectionString = \u0026#34;\u0026lt;your_connection_string\u0026gt;\u0026#34;;\rvar requestQueueName = \u0026#34;sample.request\u0026#34;;\rvar replyQueueName = \u0026#34;sample.reply\u0026#34;;\r// create queues\r await Task.WhenAll(CreateQueueAsync(connectionString, requestQueueName, false), CreateQueueAsync(connectionString, replyQueueName, true));\r}\r// /!\\ IT\u0026#39;S JUST FOR DEMO\rstatic async Task CreateQueueAsync(string connectionString, string queueName, bool requiresSession)\r{\rvar managementClient = new ManagementClient(connectionString);\rif (await managementClient.QueueExistsAsync(queueName))\r{\rawait managementClient.DeleteQueueAsync(queueName);\r}\rawait managementClient.CreateQueueAsync(new QueueDescription(queueName)\r{\rRequiresSession = requiresSession\r});\r}\r  Pour la d√©monstration chaque service sera simul√© par un thread.\nThread de l\u0026rsquo;envoyeur (Bob) Bob envoie un message avec la propri√©t√© ReplyTo √©gal au chemin d\u0026rsquo;acc√®s de la file d\u0026rsquo;attente de r√©ponse et ReplyToSessionId √©gal √† l\u0026rsquo;identifiant de sa session.\nUne fois le message envoy√© Bob √©coute sa session.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  public static class SampleThreadFactory\r{\r...\rpublic static Thread CreateRequestor(string threadId, string connectionString, string requestQueueName, string replyQueueName)\r{\rreturn new Thread(async () =\u0026gt;\r{\r/*** send message ***/\rvar messageSender = new MessageSender(connectionString, requestQueueName);\rvar sessionId = \u0026#34;session-\u0026#34; + threadId;\rvar message = new Message\r{\rMessageId = threadId,\rReplyTo = new ServiceBusConnectionStringBuilder(connectionString) { EntityPath = replyQueueName }.ToString(),\rReplyToSessionId = sessionId,\rTimeToLive = TimeSpan.FromMinutes(2)\r};\rawait messageSender.SendAsync(message);\rawait messageSender.CloseAsync();\r/*** send message ***/\r/*** wait response ***/\rSessionClient sessionClient = new SessionClient(connectionString, replyQueueName);\rvar session = await sessionClient.AcceptMessageSessionAsync(sessionId);\rMessage sessionMessage = await session.ReceiveAsync(TimeSpan.FromMinutes(2));\rawait session.CompleteAsync(sessionMessage.SystemProperties.LockToken);\rawait session.CloseAsync();\rawait sessionClient.CloseAsync();\r/*** wait response ***/\r});\r}\r}\r  Thread du r√©pondeur (Eve) Eve √©coute la file d\u0026rsquo;attente sur laquelle Bob envoie ses messages.\nUne fois qu\u0026rsquo;un message est intercept√©, elle envoie un message de r√©ponse sur le chemin d\u0026rsquo;acc√®s d√©fini par la propri√©t√© ReplyTo.\nLe message de r√©ponse envoy√© doit contenir la propri√©t√© SessionId d√©finie √† partir la propri√©t√© ReplyToSessionId du message intercept√© (et pour le suivi ainsi qu\u0026rsquo;une standardisation, la propri√©t√© CorrelationId est √©gal √† l\u0026rsquo;id (MessageId) du message r√©ceptionn√©).\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  public static class SampleThreadFactory\r{\rpublic static Thread CreateReplier(string threadId, string connectionString, string requestQueueName)\r{\rreturn new Thread(() =\u0026gt;\r{\rvar messageReceiver = new MessageReceiver(connectionString, requestQueueName);\rmessageReceiver.RegisterMessageHandler(\rasync (message, cancellationToken) =\u0026gt;\r{\rvar connectionStringBuilder = new ServiceBusConnectionStringBuilder(message.ReplyTo);\rvar replyToQueue = new MessageSender(connectionStringBuilder);\rvar replyMessage = new Message(Encoding.UTF8.GetBytes($\u0026#34;processed by {threadId}\u0026#34;))\r{\rCorrelationId = message.MessageId,\rSessionId = message.ReplyToSessionId,\rTimeToLive = TimeSpan.FromMinutes(1)\r};\r/**** Simulate an action *****/\rawait Task.Delay(new Random().Next(1000, 2000), cancellationToken);\r/*******************************/\rawait replyToQueue.SendAsync(replyMessage);\r},\rnew MessageHandlerOptions(args =\u0026gt; throw args.Exception)\r{\rMaxConcurrentCalls = 10\r});\r});\r}\r  Initialisation du contexte de test 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  static async Task Main()\r{\rvar connectionString = \u0026#34;\u0026lt;your_connection_string\u0026gt;\u0026#34;;\rvar requestQueueName = \u0026#34;sample.request\u0026#34;;\rvar replyQueueName = \u0026#34;sample.reply\u0026#34;;\r// create queues\r await Task.WhenAll(CreateQueueAsync(connectionString, requestQueueName, false), CreateQueueAsync(connectionString, replyQueueName, true));\r// start all\r Parallel.ForEach(new List\u0026lt;Thread\u0026gt;\r{\rSampleThreadFactory.CreateRequestor(\u0026#34;REQUESTOR-BOB\u0026#34;, connectionString, requestQueueName, replyQueueName),\rSampleThreadFactory.CreateReplier(\u0026#34;REPLIER-EVE\u0026#34;, connectionString, requestQueueName)\r}, (thread, state) =\u0026gt; thread.Start());\rConsole.Read();\r}\r  R√©sulat Et aucun probl√®me avec plusieurs envoyeurs, chacun re√ßoit le message de r√©ponse qui lui est destin√©.\nVoil√†!\nSources Repository  https://github.com/Golapadeog/sample-azure-service-bus-request-response  Documentation  https://www.enterpriseintegrationpatterns.com/patterns/messaging/RequestReplyJmsExample.html https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-amqp-request-response https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-messages-payloads https://docs.microsoft.com/en-us/azure/service-bus-messaging/message-sessions https://docs.microsoft.com/en-us/azure/service-bus-messaging/service-bus-quotas https://en.wikipedia.org/wiki/Request%E2%80%93response https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html  ","description":"","id":11,"section":"posts","tags":["dotnet","csharp","azure","pattern"],"title":"[Azure] Pattern Request/Response avec Azure Service Bus","uri":"https://blog.jeremylandon.com/fr/2020/03/22/azure-pattern-request-response-avec-azure-service-bus/"},{"content":"Lors d\u0026rsquo;une tentative d\u0026rsquo;un copier/coller (pression longue) sur un champ Text sur IOS le message suivant peut apparaitre :\n The getter \u0026lsquo;pasteButtonLabel\u0026rsquo; was called on null.\nReceiver: null\nTried calling: pasteButtonLabel\r Si tel est le cas, c\u0026rsquo;est qu\u0026rsquo;IOS n\u0026rsquo;arrive tout simplement pas √† trouver la localisation adapt√©e pour les boutons d\u0026rsquo;actions.\nPour corriger ce point il suffit de cr√©er un LocalizationsDelegate personnalis√© pour IOS :\n1 2 3 4 5 6 7 8 9 10 11 12  class CupertinoLocalisationsDelegate extends LocalizationsDelegate\u0026lt;CupertinoLocalizations\u0026gt; {\rconst CupertinoLocalisationsDelegate();\r@override\rbool isSupported(Locale locale) =\u0026gt; true;\r@override\rFuture\u0026lt;CupertinoLocalizations\u0026gt; load(Locale locale) =\u0026gt; DefaultCupertinoLocalizations.load(locale);\r@override\rbool shouldReload(CupertinoLocalisationsDelegateold) =\u0026gt; false;\r}\r  Et de l\u0026rsquo;utiliser au niveau de la MaterialApp :\n1 2 3 4 5 6 7  MaterialApp(\r...\rlocalizationsDelegates: const \u0026lt;LocalizationsDelegate\u0026lt;dynamic\u0026gt;\u0026gt;[\rGlobalMaterialLocalizations.delegate,\rGlobalWidgetsLocalizations.delegate,\r+ CupertinoLocalisationsDelegate(),\r ], ...\r  A noter qu\u0026rsquo;avec cette classe la localisation utilis√©e pour les actions sera celle par d√©faut du t√©l√©phone.\nPour corriger ce point il faut modifier la logique de la m√©thode load(Local locale) qui permet de d√©finir la localisation.\r ","description":"Exception : The getter \"pasteButtonLabel\" was called on null","id":12,"section":"posts","tags":["flutter","dart","ios","mobile","exception"],"title":"[Flutter] Exception lors d'une copie sous IOS","uri":"https://blog.jeremylandon.com/fr/2019/10/21/flutter-exception-lors-dune-copie-sous-ios/"}]